2025-07-22 10:24:38.028 [main] INFO  com.cellenta.cgf.CgfApplication - Starting CgfApplication using Java 21.0.1 with PID 44041 (/Users/asmeydan/Desktop/i2i/cgf/target/classes started by asmeydan in /Users/asmeydan/Desktop/i2i/cgf)
2025-07-22 10:24:38.030 [main] INFO  com.cellenta.cgf.CgfApplication - No active profile set, falling back to 1 default profile: "default"
2025-07-22 10:24:38.331 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-07-22 10:24:38.340 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 5 ms. Found 0 JPA repository interfaces.
2025-07-22 10:24:38.570 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8080 (http)
2025-07-22 10:24:38.577 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8080"]
2025-07-22 10:24:38.578 [main] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
2025-07-22 10:24:38.579 [main] INFO  o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-07-22 10:24:38.605 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2025-07-22 10:24:38.605 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 557 ms
2025-07-22 10:24:38.774 [main] INFO  o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-22 10:24:38.805 [main] INFO  org.hibernate.Version - HHH000412: Hibernate ORM core version 6.6.18.Final
2025-07-22 10:24:38.824 [main] INFO  o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-22 10:24:38.953 [main] INFO  o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-22 10:24:38.965 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2025-07-22 10:24:39.847 [main] INFO  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@44b9c7c4
2025-07-22 10:24:39.848 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2025-07-22 10:24:40.112 [main] WARN  org.hibernate.orm.deprecation - HHH90000025: OracleDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-07-22 10:24:40.296 [main] INFO  o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 21.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-22 10:24:40.455 [main] INFO  o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-22 10:24:40.457 [main] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 10:24:40.587 [main] WARN  o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-07-22 10:24:40.791 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8080"]
2025-07-22 10:24:40.796 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8080 (http) with context path '/'
2025-07-22 10:24:40.801 [main] INFO  com.cellenta.cgf.CgfApplication - Started CgfApplication in 2.945 seconds (process running for 3.346)
2025-07-22 10:44:27.688 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
2025-07-22 10:44:27.699 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
2025-07-22 10:44:27.705 [SpringApplicationShutdownHook] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 10:44:27.708 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown initiated...
2025-07-22 10:44:28.323 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown completed.
2025-07-22 10:44:30.331 [main] INFO  com.cellenta.cgf.CgfApplication - Starting CgfApplication using Java 21.0.1 with PID 44268 (/Users/asmeydan/Desktop/i2i/cgf/target/classes started by asmeydan in /Users/asmeydan/Desktop/i2i/cgf)
2025-07-22 10:44:30.332 [main] INFO  com.cellenta.cgf.CgfApplication - No active profile set, falling back to 1 default profile: "default"
2025-07-22 10:44:30.628 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-07-22 10:44:30.637 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 5 ms. Found 0 JPA repository interfaces.
2025-07-22 10:44:30.834 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8080 (http)
2025-07-22 10:44:30.842 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8080"]
2025-07-22 10:44:30.843 [main] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
2025-07-22 10:44:30.843 [main] INFO  o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-07-22 10:44:30.864 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2025-07-22 10:44:30.865 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 510 ms
2025-07-22 10:44:31.007 [main] INFO  o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-22 10:44:31.032 [main] INFO  org.hibernate.Version - HHH000412: Hibernate ORM core version 6.6.18.Final
2025-07-22 10:44:31.049 [main] INFO  o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-22 10:44:31.172 [main] INFO  o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-22 10:44:31.183 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2025-07-22 10:44:32.121 [main] INFO  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@5e3d2765
2025-07-22 10:44:32.122 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2025-07-22 10:44:32.376 [main] WARN  org.hibernate.orm.deprecation - HHH90000025: OracleDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-07-22 10:44:32.552 [main] INFO  o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 21.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-22 10:44:32.693 [main] INFO  o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-22 10:44:32.694 [main] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 10:44:32.820 [main] WARN  o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-07-22 10:44:33.004 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8080"]
2025-07-22 10:44:33.010 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8080 (http) with context path '/'
2025-07-22 10:44:33.014 [main] INFO  com.cellenta.cgf.CgfApplication - Started CgfApplication in 2.87 seconds (process running for 3.193)
2025-07-22 10:51:05.511 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
2025-07-22 10:51:05.517 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
2025-07-22 10:51:05.522 [SpringApplicationShutdownHook] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 10:51:05.526 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown initiated...
2025-07-22 10:51:07.499 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown completed.
2025-07-22 10:51:09.320 [main] INFO  com.cellenta.cgf.CgfApplication - Starting CgfApplication using Java 21.0.1 with PID 44345 (/Users/asmeydan/Desktop/i2i/cgf/target/classes started by asmeydan in /Users/asmeydan/Desktop/i2i/cgf)
2025-07-22 10:51:09.321 [main] INFO  com.cellenta.cgf.CgfApplication - No active profile set, falling back to 1 default profile: "default"
2025-07-22 10:51:09.614 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-07-22 10:51:09.622 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 4 ms. Found 0 JPA repository interfaces.
2025-07-22 10:51:09.817 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8080 (http)
2025-07-22 10:51:09.824 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8080"]
2025-07-22 10:51:09.825 [main] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
2025-07-22 10:51:09.825 [main] INFO  o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-07-22 10:51:09.848 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2025-07-22 10:51:09.849 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 506 ms
2025-07-22 10:51:09.984 [main] INFO  o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-22 10:51:10.007 [main] INFO  org.hibernate.Version - HHH000412: Hibernate ORM core version 6.6.18.Final
2025-07-22 10:51:10.019 [main] INFO  o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-22 10:51:10.134 [main] INFO  o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-22 10:51:10.145 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2025-07-22 10:51:11.190 [main] INFO  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@5e3d2765
2025-07-22 10:51:11.191 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2025-07-22 10:51:11.445 [main] WARN  org.hibernate.orm.deprecation - HHH90000025: OracleDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-07-22 10:51:11.626 [main] INFO  o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 21.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-22 10:51:11.771 [main] INFO  o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-22 10:51:11.772 [main] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 10:51:11.895 [main] WARN  o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-07-22 10:51:12.083 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8080"]
2025-07-22 10:51:12.088 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8080 (http) with context path '/'
2025-07-22 10:51:12.093 [main] INFO  com.cellenta.cgf.CgfApplication - Started CgfApplication in 2.955 seconds (process running for 3.245)
2025-07-22 11:00:17.540 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
2025-07-22 11:00:17.547 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
2025-07-22 11:00:17.552 [SpringApplicationShutdownHook] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 11:00:17.554 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown initiated...
2025-07-22 11:00:18.136 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown completed.
2025-07-22 11:19:19.892 [main] INFO  com.cellenta.cgf.CgfApplication - Starting CgfApplication using Java 21.0.1 with PID 44765 (/Users/asmeydan/Desktop/i2i/cgf/target/classes started by asmeydan in /Users/asmeydan/Desktop/i2i/cgf)
2025-07-22 11:19:19.893 [main] INFO  com.cellenta.cgf.CgfApplication - No active profile set, falling back to 1 default profile: "default"
2025-07-22 11:19:20.199 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-07-22 11:19:20.209 [main] INFO  o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 6 ms. Found 0 JPA repository interfaces.
2025-07-22 11:19:20.412 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8080 (http)
2025-07-22 11:19:20.419 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8080"]
2025-07-22 11:19:20.420 [main] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
2025-07-22 11:19:20.420 [main] INFO  o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-07-22 11:19:20.442 [main] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2025-07-22 11:19:20.442 [main] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 527 ms
2025-07-22 11:19:20.583 [main] INFO  o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-22 11:19:20.608 [main] INFO  org.hibernate.Version - HHH000412: Hibernate ORM core version 6.6.18.Final
2025-07-22 11:19:20.623 [main] INFO  o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-22 11:19:20.745 [main] INFO  o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-22 11:19:20.757 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2025-07-22 11:19:21.575 [main] INFO  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@77cddc0c
2025-07-22 11:19:21.576 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2025-07-22 11:19:21.824 [main] WARN  org.hibernate.orm.deprecation - HHH90000025: OracleDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
2025-07-22 11:19:22.007 [main] INFO  o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 21.0
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-22 11:19:22.160 [main] INFO  o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-22 11:19:22.162 [main] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 11:19:22.292 [main] WARN  o.s.b.a.o.j.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-07-22 11:19:22.511 [main] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8080"]
2025-07-22 11:19:22.517 [main] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8080 (http) with context path '/'
2025-07-22 11:19:22.524 [main] INFO  com.cellenta.cgf.CgfApplication - Started CgfApplication in 2.819 seconds (process running for 3.192)
2025-07-22 11:33:12.017 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 3 (/34.38.128.100:9094) could not be established. Node may not be available.
2025-07-22 11:37:35.237 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.PoolBase - HikariPool-1 - Failed to validate connection oracle.jdbc.driver.T4CConnection@64e023e7 (G/Ç Hatası: Invalid Operation, NOT Connected). Possibly consider using a shorter maxLifetime value.
2025-07-22 11:37:35.238 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=9m13s488ms).
2025-07-22 11:37:45.693 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 399: The coordinator is not aware of this member.
2025-07-22 11:37:45.695 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 11:37:45.752 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=423, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1604, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 11:37:45.753 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=399, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1582, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2025-07-22 11:39:19.200 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m43s962ms).
2025-07-22 11:39:19.554 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 11:39:19.554 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 2 (/34.38.128.100:9093) could not be established. Node may not be available.
2025-07-22 11:39:22.169 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 424: The coordinator is not aware of this member.
2025-07-22 11:39:22.170 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 11:39:22.247 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 11:39:22.247 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=424, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2025-07-22 11:44:43.367 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=3m54s149ms).
2025-07-22 11:44:50.467 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 11:44:50.473 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 11:44:50.474 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 11:44:50.474 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 11:48:47.543 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 11:48:47.544 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 2 (/34.38.128.100:9093) could not be established. Node may not be available.
2025-07-22 11:48:48.546 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 11:48:48.547 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 2 (/34.38.128.100:9093) could not be established. Node may not be available.
2025-07-22 11:48:49.434 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 11:48:49.438 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 11:48:49.438 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 11:48:49.438 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 11:49:03.268 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=4m19s900ms).
2025-07-22 11:53:33.031 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.PoolBase - HikariPool-1 - Failed to validate connection oracle.jdbc.driver.T4CConnection@4305d75e (G/Ç Hatası: Invalid Operation, NOT Connected). Possibly consider using a shorter maxLifetime value.
2025-07-22 11:53:34.129 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 11:53:34.179 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 11:53:34.179 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 11:53:34.180 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 11:53:37.665 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=3m34s390ms).
2025-07-22 12:02:35.589 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 12:02:35.594 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 12:02:35.594 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 12:02:35.594 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 12:07:03.698 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=13m26s33ms).
2025-07-22 12:11:39.264 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 12:11:39.317 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 12:11:39.317 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 12:11:39.318 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 12:11:58.762 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=4m55s64ms).
2025-07-22 12:16:12.267 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 12:16:12.268 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 12:16:12.306 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 12:16:12.306 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2025-07-22 12:25:20.095 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=13m21s333ms).
2025-07-22 12:34:10.238 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.PoolBase - HikariPool-1 - Failed to validate connection oracle.jdbc.driver.T4CConnection@47241177 (G/Ç Hatası: Invalid Operation, NOT Connected). Possibly consider using a shorter maxLifetime value.
2025-07-22 12:34:13.174 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 12:34:13.179 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 12:34:13.179 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 12:34:13.179 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 12:38:46.681 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.PoolBase - HikariPool-1 - Failed to validate connection oracle.jdbc.driver.T4CConnection@33754461 (G/Ç Hatası: Invalid Operation, NOT Connected). Possibly consider using a shorter maxLifetime value.
2025-07-22 12:43:16.734 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=17m56s639ms).
2025-07-22 12:47:53.368 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 12:47:53.375 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 12:47:53.375 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 12:47:53.375 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 12:56:53.784 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.PoolBase - HikariPool-1 - Failed to validate connection oracle.jdbc.driver.T4CConnection@6528720a (Kapalı Bağlantı). Possibly consider using a shorter maxLifetime value.
2025-07-22 12:57:03.397 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=13m16s684ms).
2025-07-22 13:04:58.176 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 3 (/34.38.128.100:9094) could not be established. Node may not be available.
2025-07-22 13:04:58.626 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 13:04:58.956 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 13:04:58.956 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 2 (/34.38.128.100:9093) could not be established. Node may not be available.
2025-07-22 13:04:59.330 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 3 (/34.38.128.100:9094) could not be established. Node may not be available.
2025-07-22 13:04:59.563 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 13:05:00.919 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 13:05:00.924 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-1 at offset 428: The coordinator is not aware of this member.
2025-07-22 13:05:00.925 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 13:05:00.925 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 13:05:16.383 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=8m12s986ms).
2025-07-22 13:16:24.087 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 1 (/34.38.128.100:9092) could not be established. Node may not be available.
2025-07-22 13:16:24.088 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Connection to node 2 (/34.38.128.100:9093) could not be established. Node may not be available.
2025-07-22 13:16:25.358 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] The metadata response from the cluster reported a recoverable issue with correlation id 5196 : {chf-to-cgf=LEADER_NOT_AVAILABLE}
2025-07-22 13:16:25.361 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-0
2025-07-22 13:16:25.366 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-1
2025-07-22 13:16:25.423 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-1
2025-07-22 13:16:25.484 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-1
2025-07-22 13:16:25.552 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-1
2025-07-22 13:16:25.594 [kafka-coordinator-heartbeat-thread | UsageRecordConsumerGroup] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-0 at offset 1605: The coordinator is not aware of this member.
2025-07-22 13:16:25.595 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}, chf-to-cgf-0=OffsetAndMetadata{offset=1605, leaderEpoch=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2025-07-22 13:16:25.595 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 13:16:25.600 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-1=OffsetAndMetadata{offset=428, leaderEpoch=0, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 13:16:35.448 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] The metadata response from the cluster reported a recoverable issue with correlation id 5215 : {chf-to-cgf=LEADER_NOT_AVAILABLE}
2025-07-22 13:16:52.124 [HikariPool-1:housekeeper] WARN  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=2m5s642ms).
2025-07-22 13:26:30.997 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.. Will continue to join group.
2025-07-22 13:26:31.052 [Thread-3] ERROR o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Offset commit failed on partition chf-to-cgf-0 at offset 0: Specified group generation id is not valid.
2025-07-22 13:26:31.053 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
2025-07-22 13:26:31.053 [Thread-3] WARN  o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Asynchronous auto-commit of offsets {chf-to-cgf-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}} failed: Offset commit cannot be completed since the consumer member's generation is already stale, meaning it has already participated another rebalance and got a new generation. You can try completing the rebalance by calling poll() and then retry commit again
2025-07-22 13:26:46.811 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-0
2025-07-22 13:26:46.919 [Thread-3] WARN  o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] The metadata response from the cluster reported a recoverable issue with correlation id 6635 : {chf-to-cgf=LEADER_NOT_AVAILABLE}
2025-07-22 13:26:46.921 [Thread-3] WARN  o.a.k.c.c.internals.FetchCollector - [Consumer clientId=consumer-UsageRecordConsumerGroup-1, groupId=UsageRecordConsumerGroup] Received unknown topic or partition error in fetch for partition chf-to-cgf-0
2025-07-22 13:26:59.379 [SpringApplicationShutdownHook] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
2025-07-22 13:26:59.391 [tomcat-shutdown] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
2025-07-22 13:26:59.398 [SpringApplicationShutdownHook] INFO  o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-22 13:26:59.402 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown initiated...
2025-07-22 13:27:00.004 [SpringApplicationShutdownHook] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Shutdown completed.
